from forge.sdk import (
    Agent,
    AgentDB,
    ForgeLogger,
    Step,
    StepRequestBody,
    Task,
    TaskRequestBody,
    Workspace,    
    PromptEngine,	
    chat_completion_request,	
    ChromaMemStore	
)
import json	
import pprint
import traceback
from typing import Tuple
import re
LOG = ForgeLogger(__name__)



""" 
ATTENTION: æ³¨æ„:
å¼•å…¥å…¨å±€å˜é‡,æœ¬å˜é‡ç”¨äºæŒ‡å®šæ˜¯å¦å¼€å§‹debug
"""
debug = False
""" 
ATTENTION: æ³¨æ„ï¼š
ç”±äºéœ€è¦è®°å½•å¯¹è¯æ¡†ï¼Œå› æ­¤å¯¹è¯æ¡†ä¸ºä¸€æ¬¡æ€§çš„ï¼
åŒæ—¶ï¼Œç”±äºå¤šçº¿ç¨‹çš„é—®é¢˜ï¼Œä¸ºäº†æ­£ç¡®çš„ä¿å­˜ç»“æœï¼Œè¯·ä¸€å®šä¸€å®šåˆ†å¼€è¯¢é—®
"""

""" 
å…¨å±€éœ€è¦ä¿®æ”¹çš„å˜é‡
result_folder: ç”¨äºä¿å­˜è®¿é—®çš„ç»“æœ
target_folder: çœŸæ­£çš„ä¿å­˜è·¯å¾„ï¼Œä¼šéšç€åç»­æ“ä½œæ”¹å˜
"""
result_folder: str = "/home/wind/Desktop/projects/Redanduncy_AutoGPT/autogpts/mytest/results"

""" 
å¼•å…¥å¯ä»¥æ‰§è¡Œé¢å¤–pythonä»£ç å‡½æ•°
"""
def execute_additional_code(code) -> Tuple[bool, str]:
    from io import StringIO
    import sys
    # Capture the standard output
    old_stdout = sys.stdout
    new_stdout = StringIO()
    sys.stdout = new_stdout
    
    try:
        # Execute the additional code
        exec(code)
        result = new_stdout.getvalue()  # Get the output
        status = True
    except Exception as e:
        result = f"Error: {str(e)}"
        status = False 
    
    # Restore the standard output
    sys.stdout = old_stdout
    
    return status, result


def mkdir_result_folder(folder: str) -> None:
    import os
    os.makedirs(folder, exist_ok=True)


class ForgeAgent(Agent):
    """
    The goal of the Forge is to take care of the boilerplate code, so you can focus on
    agent design.

    There is a great paper surveying the agent landscape: https://arxiv.org/abs/2308.11432
    Which I would highly recommend reading as it will help you understand the possabilities.

    Here is a summary of the key components of an agent:

    Anatomy of an agent:
         - Profile
         - Memory
         - Planning
         - Action

    Profile:

    Agents typically perform a task by assuming specific roles. For example, a teacher,
    a coder, a planner etc. In using the profile in the llm prompt it has been shown to
    improve the quality of the output. https://arxiv.org/abs/2305.14688

    Additionally, based on the profile selected, the agent could be configured to use a
    different llm. The possibilities are endless and the profile can be selected
    dynamically based on the task at hand.

    Memory:

    Memory is critical for the agent to accumulate experiences, self-evolve, and behave
    in a more consistent, reasonable, and effective manner. There are many approaches to
    memory. However, some thoughts: there is long term and short term or working memory.
    You may want different approaches for each. There has also been work exploring the
    idea of memory reflection, which is the ability to assess its memories and re-evaluate
    them. For example, condensing short term memories into long term memories.

    Planning:

    When humans face a complex task, they first break it down into simple subtasks and then
    solve each subtask one by one. The planning module empowers LLM-based agents with the ability
    to think and plan for solving complex tasks, which makes the agent more comprehensive,
    powerful, and reliable. The two key methods to consider are: Planning with feedback and planning
    without feedback.

    Action:

    Actions translate the agent's decisions into specific outcomes. For example, if the agent
    decides to write a file, the action would be to write the file. There are many approaches you
    could implement actions.

    The Forge has a basic module for each of these areas. However, you are free to implement your own.
    This is just a starting point.
    """

    def __init__(self, database: AgentDB, workspace: Workspace):
        """
        The database is used to store tasks, steps and artifact metadata. The workspace is used to
        store artifacts. The workspace is a directory on the file system.

        Feel free to create subclasses of the database and workspace to implement your own storage
        """
        super().__init__(database, workspace)

    async def create_task(self, task_request: TaskRequestBody) -> Task:
        """
        The agent protocol, which is the core of the Forge, works by creating a task and then
        executing steps for that task. This method is called when the agent is asked to create
        a task.

        We are hooking into function to add a custom log message. Though you can do anything you
        want here.
        """
        task = await super().create_task(task_request)
        LOG.info(
            f"ğŸ“¦ Task created: {task.task_id} input: {task.input[:40]}{'...' if len(task.input) > 40 else ''}"
        )
        """ 
        åˆ›å»ºä¿å­˜è·¯å¾„: é—®é¢˜å + åˆ›å»ºæ—¶é—´
        """
        from datetime import datetime
        current_time = datetime.now()
        current_time_str = current_time.strftime("%Y-%m-%d %H:%M:%S")
        self.target_folder = result_folder + "/" + task.input + ":" + current_time_str
        mkdir_result_folder(self.target_folder)
        """ 
        åˆ›å»ºä¿å­˜çš„æ–‡ä»¶
        """
        self.target_file = self.target_folder + "/" + task.input + ".md" 
        with open(self.target_file, "w") as f:
            pass
        return task

    async def execute_step(self, task_id: str, step_request: StepRequestBody, memory_list: list, code_list: list, execution_result_list: list) -> Step:
        if debug:
            traceback.print_stack()
        # Firstly we get the task this step is for so we can access the task input
        task = await self.db.get_task(task_id)

        # Initialize the PromptEngine with the "gpt-3.5-turbo" model
        prompt_engine = PromptEngine("gpt-3.5-turbo")

        # Load the system and task prompts
        system_prompt = prompt_engine.load_prompt("system-format")

        # Initialize the messages list with the system prompt
        """ æ„å»ºmessagesè¯·å‚è€ƒ https://help.openai.com/en/articles/7042661-chatgpt-api-transition-guide """
        messages = [
            {"role": "system", "content": system_prompt},
        ]
        """ è£…è½½å¯¹è¯è®°å½•,æš‚ä¸ä½¿ç”¨ """
        step_list, temp = self.db._list_steps(task_id)
        for _step in step_list:
            messages.append({"role": "user", "content":_step.input})
            messages.append({"role": "assistant", "content":_step.output})

        
        # å¦‚æœexecution_result_list == ['','','']ï¼Œè¯´æ˜æ­¤æ—¶è¿˜æ²¡æœ‰æ‰§è¡Œï¼Œé‚£ä¹ˆä»»åŠ¡ä»taskä¸­è¿›è¡Œè·å–
        if memory_list == [False,False,False]:
            # Define the task parameters
            task_kwargs = {
                "task": task.input,
                "abilities": self.abilities.list_abilities_for_prompt(),
            }

            # Load the task prompt with the defined task parameters
            task_prompt = prompt_engine.load_prompt("task-step", **task_kwargs)
            step = await self.db.create_step(
                task_id=task_id, input=step_request, is_last=True
            )

            # Append the task prompt to the messages list
        # elseè¡¨æ˜æ­¤æ—¶å·²ç»è¿›è¡Œäº†æ‰§è¡Œï¼Œé‚£ä¹ˆç›´æ¥è¿›è¡Œé—®é—®é¢˜
        else: 
            # 
            task_prompt = ""
            # è¿™é‡Œçš„task_promptæ„å»ºæ–¹å¼æœ‰é—®é¢˜ï¼Œå½“å›ç­”ä¸å†å­˜åœ¨å…¶ä»–çš„expertçš„æ—¶å€™ï¼Œåº”è¯¥ä¸å†é‡å¤è¯¥expertçš„å†…å®¹
            # for index in range(len(execution_result_list)):
                # if execution_result_list[index] != '':
            # è¿™é‡Œè·å–æ­£ç¡®çš„åšæ³•ï¼Œè€ƒè™‘messagesçš„æœ€åä¸€ä¸ªå…ƒç´ ï¼Œæœ€åä¸€ä¸ªå…ƒç´ æ˜¯æ¥è‡ªäºgptçš„å›ç­”ï¼Œè·å–gptå›ç­”çš„ç´¢å¼•
            index_pattern = r"expert \d"
            keys_iterator = iter(messages[-1])
            for key in keys_iterator:
                index_result = re.match(index_pattern, key)
                if index_result:
                    # è·å–åºå·
                    index = int(index_result.group()[len("expert ") : len("expert ") + 1])
                    task_prompt = task_prompt + f"The code execution result from expert {index+1} is: " + execution_result_list[index] + '\n'
            # ä¸‹é¢æ³¨é‡Šå†…å®¹ä¸ºå®Œå…¨é”™è¯¯çš„åšæ³•ï¼Œè¯·å¼•ä»¥ä¸ºé‰´
            # ä½¿ç”¨ç‹¬ç‰¹åšæ³•ä¿æŒé—®é¢˜ç¨³å®šï¼Œç»è¿‡éªŒè¯å®Œå…¨æ­£ç¡®ï¼Œè€Œä¸”å¼•å‘æ„æƒ³ä¸åˆ°çš„æˆåŠŸï¼
            # step.input = task_prompt
            # ä¿®æ”¹step_request
            #
            orignal_text = step_request.input
            step_request.input = task_prompt
            step = await self.db.create_step(
                task_id=task_id, input=step_request, is_last=True
            )
            step.input = orignal_text
            
        messages.append({"role": "user", "content": task_prompt})
        print("--------------------------------------")
        print("The following is messages")
        print(messages)
        print("--------------------------------------")
        # Create a new step in the database
        # éœ€è¦æ³¨æ„åˆ°åœ¨dbé‡Œé¢æ­£å¼ä¿å­˜çš„æ˜¯StepModelï¼Œ è¿™é‡Œçš„è¿”å›ç»“æœè¯•è®²StepModelæ”¹ä¸ºStepç±»ï¼Œå› æ­¤åœ¨è¿™é‡Œæ— è®ºå¦‚ä½•æ€ä¹ˆä¿®æ”¹stepï¼Œéƒ½ä¸ä¼šå½±å“åŸæœ¬ä¿å­˜çš„å†…å®¹
        # Class step
        
        """ä»¥ä¸‹çš„æ³¨é‡Šä¸ºï¼Œè·å–step_listï¼Œ_step.inputä¸ºè¾“å…¥é—®é¢˜ï¼Œ_step.outputä¸ºå›ç­”ç»“æœ"""
        # step_list, temp = self.db._list_steps(task_id)
        # for _step in step_list:
        #     print(_step.input)
        #     print(_step.output)
        # Log the message
        LOG.info(f"\tâœ… Final Step completed: {step.step_id} input: {step.input[:19]}")
        
        try:
            # Define the parameters for the chat completion request
            chat_completion_kwargs = {
                "messages": messages,
                "model": "gpt-3.5-turbo",
            }
            # Make the chat completion request and parse the response
            """ chat_responseçš„æ ¼å¼ç¬¦åˆurl: https://platform.openai.com/docs/api-reference/chat/object """
            """ æš‚æ—¶æ€§æ³¨é‡Š """
            chat_response = await chat_completion_request(**chat_completion_kwargs)
            # answer = json.loads(chat_response["choices"][0]["message"]["content"])
            answer = chat_response["choices"][0]["message"]["content"]
            memory_list = [True, True, True]
            # answer = '''
            # {
            #     "expert 1": "```a = 1\\nb = 1\\nprint(a+b)```",
            #     "expert 2": "```a = 1\\nb = 1\\nprint(a+b)```",
            #     "expert 3": "```a = 1\\nb = 1\\nprint(a+b)```"
            # }
            # '''
            # Log the answer for debugging purposes
            LOG.info(pprint.pformat(answer))

        except json.JSONDecodeError as e:
            # Handle JSON decoding errors
            LOG.error(f"Unable to decode chat response: {chat_response}")
        except Exception as e:
            # Handle other exceptions
            LOG.error(f"Unable to generate chat response: {e}")
        """ 
        ç°åœ¨å·²ç»è·å–åˆ°ä¸“å®¶çš„å›ç­”ï¼Œå°è¯•è§£æ
        """
        index_pattern = r"expert \d"
        # execution_result_list = ['', '', '']
        try:
            answer_json = json.loads(answer)
        except json.JSONDecodeError:
            print("The answer is not json format.")
        keys_iterator = iter(answer_json)
        for key in keys_iterator:
            index_result = re.match(index_pattern, key)
            if index_result:
                # è·å–åºå·
                index = int(index_result.group()[len("expert ") : len("expert ") + 1])
                print("-----------------------------------")
                print(f"obtaining the index: {index}")
                print("-----------------------------------")
                # è·å–ä»£ç ï¼Œä¿å­˜åœ¨somposite_codeé‡Œé¢
                split_codes = answer_json[key]["code"]
                print("-----------------------------------")
                print("The following is split codes")
                print(split_codes)
                print("-----------------------------------")
                # composite_code = ''
                # for code in split_codes:
                    # composite_code = composite_code + '\n' + code[3:-3] 
                # ä¸ä¹‹å‰çš„ä»£ç è¿›è¡Œæ‹¼æ¥
                code_list[index - 1] = code_list[index - 1] + '\n' + split_codes
                # è·å–ä»£ç çš„æ‰§è¡Œç»“æœ
                exe_status, exe_result = execute_additional_code(code_list[index - 1])
                print("-----------------------------------")
                print("The following is the execution code")
                print(code_list[index - 1])
                print("-----------------------------------")
                print("-----------------------------------")
                print("The following is exe_result")
                print(exe_result)
                print("-----------------------------------")
                execution_result_list[index - 1] = exe_result
            else:
                print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$")
                print("The key in json is not correct.")
                print("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$")
                
        # Extract the ability from the answer   
        # try:
        #     ability = answer["ability"]
        # except KeyError:
        #     ability = answer["abilities"]
        # except: 
        #     LOG.error(f"Fail to get the ability")

        # Run the ability and get the output
        # We don't actually use the output in this example
        # output = await self.abilities.run_ability(
        #     task_id, ability["name"], **ability["args"]
        # )

        # Set the step output to the "speak" part of the answer
        # step.output = answer["thoughts"]["speak"]
        step.output = answer
        """ å°†ç»“æœä¿å­˜è‡³æ–‡ä»¶ä¸­ï¼Œå½“ç„¶ç”±äºè¿™é‡Œçš„target_fileå¯èƒ½ä¸å­˜åœ¨å€¼ï¼Œå› æ­¤è¿™é‡Œä¸€å®šåšä¾‹å¤–å¤„ç† """
        try:
            with open(self.target_file, "a") as f:
                f.write("---------------------------\n")
                f.write("Question: " + step.input + "\n")
                f.write("Answer:\n" + step.output + "\n")
                f.write("---------------------------\n")
        except AttributeError:
            print("Fail to store the results into the file.")
        """ ç”¨äºå°†ç»“æœè¿›è¡Œå›ç­”è¿›è¡Œä¿å­˜ """
        self.db.change_step_output(task_id=task_id, step_id=step.step_id, output = answer)
        # Return the completed step
        return step, memory_list, code_list, execution_result_list, answer_json
